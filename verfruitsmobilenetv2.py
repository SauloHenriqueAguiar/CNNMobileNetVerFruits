# -*- coding: utf-8 -*-
"""VerFruitsMobileNetV2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qN08UFAZmKXRSy-BzEaCApSlTy5unD5y

# **Rede Neural Convolucional MobileNet**

**1- Importação de Biliotecas**
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
import numpy as np 
import pandas as pd 
from IPython.display import display, Image 
# %matplotlib inline
import os

from sklearn.model_selection import train_test_split
from sklearn import datasets
import matplotlib.image as mpimg
import keras
from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Flatten, Dropout, UpSampling2D, GlobalAveragePooling2D
from keras.models import Model

import matplotlib.pyplot as plt
from keras.utils import np_utils
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from IPython.display import Image, display
import random, os

"""**2- Instação do Kaggle**"""

!pip install -q kaggle

"""**3- Importação do Arquivo Json Kaggle**"""

from google.colab import files

files.upload()

"""**4- Criação pasta no drive arquivo kaggle**"""

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

"""**5- Baixar o dataset direto do kaggle**"""

! kaggle datasets download -d sriramr/fruits-fresh-and-rotten-for-classification

"""**6- Extrai arquivos Zip(dataset)**"""

!unzip fruits-fresh-and-rotten-for-classification.zip

"""**7- Obtem os rotulos dos dados de treinamento**"""

labels = os.listdir('/content/dataset/train')
labels

"""**8- Mostra de forma aleatória algumas imagens de treinamento e tambem o tamanho de cada pasta de frutas de treinamento**"""

num = []

for i in labels:
  path = '/content/dataset/train/{0}/'.format(i)
  folder_data = os.listdir(path)
  k=0
  print('\n', i.upper())
  for j in folder_data:
    if(k<2):
      display(Image(path+j))
    k=k+1
  num.append(k)
  print('there are ', k,' images in ', i, 'class')

"""**9-Divide os diretórios treinamento e validação(treino/teste)**"""

train_dir = os.path.join('/content/dataset/train', 'train')
validation_dir = os.path.join('/content/dataset/test', 'validation')

"""**10- Lista as classes do Treino**"""

!ls /content/dataset/test

"""**11-Verifica a quantidade de imagens do teste**"""

test_imgs_count = sum([len(files) for r, d, files in os.walk("/content/dataset/test")])
test_imgs_count

"""**12-Verifica a quantidade de imagens do treino**"""

train_imgs_count = sum([len(files) for r, d, files in os.walk("/content/dataset/train")])
train_imgs_count

"""**13- Tamanho do Lote**"""

#modificar pra ver o resultado!!!
batch_size_train = 71
batch_size_test = 1

"""**14- Verificar imagens**"""

def display20randomimages(t):
  fig=plt.figure(figsize=(8, 8))
  columns = 4
  rows = 5
  for i in range(1, columns*rows +1):
    c = "/" + str(random.choice([0,1,2,3,4,5,6,7])) + "/"
    random_filename = random.choice([
        x for x in os.listdir(t + c)
        if os.path.isfile(os.path.join(t+c, x))
    ])
    img = mpimg.imread(t+c+random_filename)
    fig.add_subplot(rows, columns, i)
    plt.imshow(img)
  plt.show()

"""**15- Reescalona os dados de treino**"""

train_datagen = ImageDataGenerator()

"""**16- Reescalona os dados do teste**"""

test_datagen = ImageDataGenerator()

"""**17- Mostra dimensão das imagens**"""

BATCH_SIZE = 32
IMG_SIZE = (160, 160)

"""**18- Definição de dados de treino**"""

train_generator = train_datagen.flow_from_directory(
    directory=r'/content/dataset/train',
    target_size=(160, 160),
    color_mode="rgb",
    batch_size=32,
    class_mode="categorical",
    shuffle=True,
    seed=42
)

"""**19- Definição de dados de teste**"""

test_generator = test_datagen.flow_from_directory(
    directory=r'/content/dataset/test',
    target_size=(160, 160),
    color_mode="rgb",
    batch_size=32,
    class_mode="categorical",
    shuffle=False,
    seed=42
)

"""**20- Definições**"""

inp = Input(shape = (160,160,3))

base_learning_rate = 0.0001

STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size

STEP_SIZE_TEST=test_generator.n//test_generator.batch_size

"""**21- Importação da MobileNetV2**"""

from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input
from keras.preprocessing import image

"""**22- Carregamento de MobileNetV2**"""

model_mobile = MobileNetV2(input_shape=(160,160,3), include_top=False, weights='imagenet')
model_mobile.trainable = False #conlega algumas camadas(só treina o topo da rede)

model_mobile.summary()

"""**23- Adiciona Algumas Camadas a Rede Mobilenet**"""

x = preprocess_input(inp)
x1 = model_mobile(x, training=False)
x2 = GlobalAveragePooling2D()(x1)
x3 = Dropout(rate=0.5)(x2)
x4 = Dense(512, activation='relu')(x3)
x5 = Dense(128, activation='relu')(x4)
out = Dense(6, activation='softmax')(x5)

"""**24- Compila Modelo MobileNetV2 com novas camadas**"""

model_mobile = Model(inputs = inp, outputs = out)
model_mobile.summary()

"""**25- Otimizadores da Rede**"""

model_mobile.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

"""**26- Treina a CNN**"""

history = model_mobile.fit_generator(generator=train_generator,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    epochs=17,
                    validation_data=test_generator,
                    validation_steps=STEP_SIZE_TEST

)

"""**27- Treina Modelo Preditivo**"""

predgen = model_mobile.predict_generator(test_generator, steps=len(test_generator), verbose=1) 
pred = np.argmax(predgen,axis = 1)
y_true=test_generator.classes

"""**28-Matriz Confusão**"""

from sklearn.metrics import confusion_matrix
CM = confusion_matrix(y_true, pred)
from mlxtend.plotting import plot_confusion_matrix

fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(15, 7))
plt.show()

"""**29- Métricas**"""

#importing accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
print('\nAccuracy: {:.2f}\n'.format(accuracy_score(y_true, pred)))

print('Micro Precision: {:.2f}'.format(precision_score(y_true, pred, average='micro')))
print('Micro Recall: {:.2f}'.format(recall_score(y_true, pred, average='micro')))
print('Micro F1-score: {:.2f}\n'.format(f1_score(y_true, pred, average='micro')))

print('Macro Precision: {:.2f}'.format(precision_score(y_true, pred, average='macro')))
print('Macro Recall: {:.2f}'.format(recall_score(y_true, pred, average='macro')))
print('Macro F1-score: {:.2f}\n'.format(f1_score(y_true, pred, average='macro')))

print('Weighted Precision: {:.2f}'.format(precision_score(y_true, pred, average='weighted')))
print('Weighted Recall: {:.2f}'.format(recall_score(y_true, pred, average='weighted')))
print('Weighted F1-score: {:.2f}'.format(f1_score(y_true, pred, average='weighted')))

from sklearn.metrics import classification_report
print('\nClassification Report\n')
print(classification_report(y_true, pred))#, target_names=['Class 0', 'Class 1', 'Class 2', 'Class 3','Class 4','Class 5']))

"""**30- Avaliando (Loss=Perda)**"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['loss','Val'], loc = 'upper left')

"""**31- Avaliando (Acurácia=Acerto)**"""

plt.plot(history.history['accuracy'],'g')
plt.plot(history.history['val_accuracy'],'b')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Acc','Val'], loc = 'upper left')